#
# Sample configuration of the booster:
#      (everything to the right of '#' is ignored)
#
# BinarySplit on each input dimension
BinarySplit
# TopdownTree optimization_criterion(1=misid,5=Gini,6=Xentropy)   No_of_features_to_sample(0=all)     min_No_of_events_per_leaf  seed_for_bootstrap(0=default,-1=generate_from_time_of_day)
TopdownTree 5 0 2000 0
# StdBackprop structure(e.g.,2:4:2:1) No_of_training_cycles  learning_rate  No_of_points_for_init(0=all)  learning_rate_for_init
StdBackprop 2:4:2:1 10 0.1 0 0.1
# Fisher order(1=linear,2=quadratic)
Fisher 1
# LogitR accuracy update_factor initialization_flag(0=from zero,1=from Fisher)
LogitR 0.001 0.5 0
# Bagger No_of_training_cycles seed_for_bootstrap(0=default,-1=generate_from_time_of_day)
# next line after Bagger entry must specify one classifier to be bagged
Bagger 50 0
TopdownTree 5 2 5 -1
# AdaBoost No_of_training_cycles mode(1=Discrete,2=Real,3=Epsilon) bag_input(0=no,1=yes) epsilon
# next line after AdaBoost entry must specify one classifier to be boosted
# In case of boosted binary splits specify
#   number of AdaBoost cycles = Ndimensions*Nsplits_per_dimension, for example:
#   AdaBoost 2500 1 0 0.01
#   BinarySplit
#   for 25-D data and 100 splits per dimension
AdaBoost 10 1 0 0.01
TopdownTree 5 0 2000 0
